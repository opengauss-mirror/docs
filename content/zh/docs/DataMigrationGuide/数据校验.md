# 使用指导书

## 1、工具介绍
openGauss数据校验工具 （gs_datachecker），包含全量数据校验以及增量数据校验。

## 2、软件架构
全量数据校验，采用JDBC方式抽取源端和目标端数据，并将抽取结果暂存到kafka中，校验服务通过抽取服务从kafka中获取指定表的抽取结果，进行校验。最后将校验结果输出到指定路径的文件文件中。

增量数据校验，通过debezium监控源端数据库的数据变更记录，抽取服务按照一定的频率定期处理debezium的变更记录，对变更记录进行统计。将统计结果发送给数据校验服务。由数据校验服务发起增量数据校验，并将校验结果输出到指定路径文件。



## 3、环境要求

### 3.1硬件要求

- 服务器数量：3台鲲鹏920服务器（2台用于数据库服务器，1台用于校验服务端，kafka服务）。
- 服务器硬件规格：
  - Memory：大于512GB。
  - CPU: Kunpeng-920 2600MHZ 128核
  - Free Disk：4块NVME硬盘，每块容量大于1TB。
  - 网卡：Hi1822千兆网卡，光纤互连。

### 3.2软件要求

​	操作系统要求：openEuler-20.03-LTS（aarch64 架构）

​	JDK ： JDK11+

​	MYSQL：要求5.7+版本

​	openGauss：openGauss3.0.0

​	数据库配置建议使用高性能环境配置。

```
查看openGauss synchronize_seqscans参数，并关闭synchronize_seqscans
show synchronize_seqscans;
gs_guc set -D datadir -c "synchronize_seqscans=off";
or
gs_guc set -N all -I all -c "synchronize_seqscans=off"
查看openGauss query_dop 参数，开启并行查询 query_dop 参数，设置并行度为8，可以根据机器情况自行配置，最大64。
gs_guc set -D datadir -c "query_dop=8";
or
gs_guc set -N all -I all -c "query_dop=8";

```



## 4、部署方式

​	两台数据库服务器，分别安装mysql数据库和opengauss数据库

​	将校验工具抽取服务部署于数据库服务器

​	一台用于部署校验服务和kafka服务

## 5、使用步骤

#### **5.1 启动Zookeeper**

```
cd {path}/confluent-7.2.0
```

```
bin/zookeeper-server-start  etc/kafka/zookeeper.properties
或者
bin/zookeeper-server-start -daemon etc/kafka/zookeeper.properties
```

#### **5.2 启动Kafka**

```
bin/kafka-server-start etc/kafka/server.properties
或者
bin/kafka-server-start -daemon etc/kafka/server.properties
```



#### **5.3 校验服务启动配置** 

```
校验服务配置 修改application.yml文件
	server.port 为校验服务web端口，默认可不修改
	logging.config  设置校验服务日志路径为config/log4j2.xml文件绝对路径
	bootstrap-servers 为kafka工作地址，默认安装可不修改
	spring.memory-monitor-enable 打印校验进程内存使用情况，默认false,不打印
	spring.check.core-pool-size: 1 并发线程数池设置，最小线程数，可不修改，默认1
    spring.check.maximum-pool-size: 4 并发线程数池设置，最大线程数，可不修改，默认4
    
	data.check.data-path 校验结果输出地址，默认配置可不修改
	data.check.source-uri 源端服务请求地址，默认配置可不修改
	data.check.sink-uri 目标端服务请求地址，默认配置可不修改
	data.check.max-retry-times 心跳等最大尝试次数，默认1000
	data.check.retry-interval-times 心跳、进度等最大间隔时间单位毫秒 10000
    data.check.auto-delete-topic: 配置是否自动删除Topic，0不删除，1校验全部完成后删除，2表校验完成后删除，默认值为2
    data.check.increment-max-diff-count: 配置增量校验最大处理差异记录数，范围[10,5000]
```

#### **5.4 源端服务启动配置**

```
源端服务配置 修改application-source.yml文件
	server.port 为源端抽取服务web端口，默认可不修改
	logging.config 设置校验服务日志路径为config/log4j2source.xml文件绝对路径
	spring.memory-monitor-enable 打印校验进程内存使用情况，默认false,不打印
	spring.check.server-uri 校验服务请求地址，默认配置可不修改
	spring.extract.schema 当前校验数据schema，mysql 数据库名称
	spring.check.core-pool-size: 1 并发线程数池设置，最小线程数，可不修改，默认1
    spring.check.maximum-pool-size: 5 并发线程数池设置，最大线程数，可不修改，默认5
    spring.check.maximum-topic-size: 3 并发最大topic数量，可不修改，默认3
    spring.check.maximum-table-slice-size: 100000 并行抽取分片表记录数，默认100000
    spring.check.extend-maximum-pool-size： 10 当大表分片数超过20时，对表级分片抽取并发线程池设置，最大线程数，可不修改，默认10
    spring.extract.query-dop 默认为8，开启表内并行查询，大于1则开启表内查询，若为opengauss，则用于设置opengauss并行查询参数。为1则不开启
	spring.extract.max-retry-times 心跳等最大尝试次数，默认1000
	spring.extract.retry-interval-times 心跳、进度等最大间隔时间单位毫秒 10000
	bootstrap-servers 为kafka工作地址，默认安装可不修改
	
	数据源配置
	工具默认采用druid数据源，用户可以自定义配置连接池参数,可根据当前校验数据库任务数量（表数量）进行调整 
	driver-class-name: 数据库驱动名称，可根据源端数据库类型配置，具体见配置文件模板
    url: jdbc连接串，可根据源端数据库类型及库名进行配置，具体见配置文件模板
    username: 源端数据库用户名
    password: 源端数据库密码，需加单引号
	initialSize: 5 默认初始连接大小
	minIdle: 10 默认最小连接池数量
	maxActive: 20 默认激活数据库连接数量
	validationQuery: jdbc保活查询语句，不修改
	
```

#### **5.5 目标端服务启动配置**

```
目标端服务配置 修改application-sink.yml文件
	server.port 为目标端抽取服务web端口，默认可不修改
	logging.config 设置校验服务日志路径为config/log4j2sink.xml文件绝对路径
	spring.memory-monitor-enable 打印校验进程内存使用情况，默认false,不打印
	spring.check.server-uri 校验服务请求地址，默认配置可不修改
	spring.extract.schema 当前校验数据schema，opengauss schema名称
	spring.check.core-pool-size: 1 并发线程数池设置，最小线程数，可不修改，默认1
    spring.check.maximum-pool-size: 5 并发线程数池设置，最大线程数，可不修改，默认5
    spring.check.maximum-topic-size: 3 并发最大topic数量，可不修改，默认3
    spring.check.maximum-table-slice-size: 100000 并行抽取分片表记录数，默认100000
    spring.check.extend-maximum-pool-size： 10 当大表分片数超过20时，表级分片抽取并发线程池设置，最大线程数，可不修改，默认10
    spring.extract.query-dop 默认为1，不开启表内并行查询，大于1则开启表内查询，若为opengauss，则用于设置opengauss并行查询参数。
	spring.extract.max-retry-times 心跳等最大尝试次数，默认1000
	spring.extract.retry-interval-times 心跳、进度等最大间隔时间单位毫秒 10000
	bootstrap-servers 为kafka工作地址，默认安装可不修改
	
	数据源配置
	工具默认采用druid数据源，用户可以自定义配置连接池参数，可根据当前校验数据库任务数量（表数量）进行调整
	driver-class-name: 数据库驱动名称，可根据目标端数据库类型配置，具体见配置文件模板
    url: jdbc连接串，可根据目标端数据库类型及库名进行配置，具体见配置文件模板
    username: 目标端数据库用户名
    password: 目标端数据库密码，需加单引号
	initialSize: 5 默认初始连接大小
	minIdle: 10 默认最小连接池数量
	maxActive: 20 默认激活数据库连接数量
```



#### **5.6 启动数据校验服务**

**后台启动命令**

```shell
nohup java  -jar datachecker-extract-0.0.1.jar --source  >/dev/null 2>&1 &

nohup java  -jar datachecker-extract-0.0.1.jar --sink >/dev/null 2>&1 &

nohup java  -jar datachecker-check-0.0.1.jar >/dev/null 2>&1 &
```

**校验服务完全启动成功后，会自动发起校验；全量校验完成后，工具会自动退出当前进程。**

#### **5.7 备注**

```
1、抽取服务在启动后，会自动加载数据库的表相关信息，如果数据量较大，则数据加载会比较耗时。
2、校验服务启动后，会检测抽取端的表数据信息是否加载完成，如果在一定时间内，未完成加载，则校验服务会自行退出。这时需要查询源端和宿端的表信息加载进度，通过日志信息查看加载进度。或者直接重新启动校验服务。
3、增量校验服务启动，需要修改源端配置文件\config\application-source.yml 中	debezium-enable:true并配置其他 debezium相关配置，服务启动即可开启增量校验服务
4、服务启动参数与部署方式，会对校验性能产生一定的影响。
   启动参数：校验服务和抽取进程 增加java虚拟机参数 -Xmx、 -Xms 参数设置各进程参数保持一致即可
   启动参数增加元空间大小设置参考值：  -XX:MaxMetaspaceSize=1024M -XX:MetaspaceSize=1024M
   GC设置参考： -XX:+UseG1GC -XX:MaxGCPauseMillis=100 -XX:+ParallelRefProcEnabled
   部署方式：将抽取服务分别部署源端和目标端的数据库节点，校验服务和kafka可以部署在单独机器上。
5、增加了对内存以及数据库连接数，与并行线程数之间的限制，通过memory-monitor-enable=true可以查看当前进程内存使用情况。
 
```

#### 5.8 校验结果说明

##### **5.8.1 校验报告组成**

​	校验报告由 进度日志、校验汇总日志、成功详情日志、失败详情日志、失败表修复报告组成。

​	

| 名称           | 说明         |
| -------------- | ------------ |
| 进度日志       | progress.log |
| 校验汇总日志   | summary.log  |
| 成功详情日志   | success.log  |
| 失败详情日志   | failed.log   |
| 失败表修复报告 | repair_*.txt |

##### **5.8.2 修复报告文件名称生成规则**

​	校验结果文件名称是由：前缀、schema、表名称、表Letter、分区号组成

​	表Letter 由起始前缀 + 表名letter两部分组成。

​	起始前缀值为0，用于确保构建的letter值不为负数。

​	表letter是由表名中的英文字母小写转换而来，我们将小写的英文字母标记为0，大写英文字母标记为1。

​	起始前缀和表名letter 共同组成一个二进制字符串，最后将该二进制串转换为16进制数字。该16进制数字极为最终获取的校验结果表Letter。

​	例如：表名 "T_test_SOME_032", 转换后的letter (0 + 1 0000 1111 ) 

​	该二进制串 0100001111 转换为16进制为 10f

##### **5.8.3 校验进度日志说明**

| 名称          | 说明                                     |
| ------------- | ---------------------------------------- |
| mode          | FULL \| INCREMENT                        |
| status        | 当前校验状态{1未开始 \| 2 进行中 3 完成} |
| tableCount    | 校验表总数量                             |
| completeCount | 当前完成校验总数                         |
| total         | 完成校验表记录总数                       |
| rows          | 当前新增完成校验表记录数量               |
| avgSpeed      | 当前校验平均速率（tps/s）                |
| cost          | 当前耗时（秒）                           |
| startTime     | 校验开始时间（yyyy-MM-dd HH:mm:ss）      |
| endTime       | 校验截止时间（yyyy-MM-dd HH:mm:ss）      |
| currentTime   | 进度当前时间（yyyy-MM-dd HH:mm:ss）      |

##### **5.8.4 校验汇总日志说明**

| 名称         | 下级名称             | 说明                                |
| ------------ | -------------------- | ----------------------------------- |
| mode         |                      | FULL \| INCREMENT                   |
| tableCount   |                      | 校验表总数量                        |
| successCount |                      | 成功表总个数                        |
| failedCount  |                      | 失败表总个数                        |
| rowCount     |                      | 行记录总数                          |
| missTable    |                      | 校验源端或目标端缺少表信息          |
|              | sinkLoss             | 目标端丢失表数量                    |
|              | sinkExcess           | 目标端多出表数量                    |
|              | miss                 | 缺失校验表数量                      |
|              | lossTables           | 丢失表列表                          |
|              | excessTables         | 多出表列表                          |
|              | sourceTableTotalSize | 源端表总数                          |
|              | sinkTableTotalSize   | 目标端表总数                        |
| cost         |                      | 校验总耗时（秒）                    |
| startTime    |                      | 校验开始时间（yyyy-MM-dd HH:mm:ss） |
| endTime      |                      | 校验截止时间（yyyy-MM-dd HH:mm:ss） |



##### **5.8.5 成功详情日志说明**

| 名称      | 说明                                    |
| --------- | --------------------------------------- |
| process   | 当前进程号                              |
| schema    | 当前校验schema                          |
| tableName | 表名称                                  |
| topic     | topic                                   |
| partition | 分区号                                  |
| rowCount  | 备用                                    |
| cost      | 校验总耗时（毫秒）                      |
| startTime | 校验开始时间（yyyy-MM-dd HH:mm:ss.SSS） |
| endTime   | 校验截止时间（yyyy-MM-dd HH:mm:ss.SSS） |
| message   | 校验成功消息                            |

##### **5.8.6 失败详情日志说明**

| 名称         | 说明                                    |
| ------------ | --------------------------------------- |
| process      | 当前进程号                              |
| schema       | 当前校验schema                          |
| tableName    | 表名称                                  |
| topic        | topic                                   |
| partition    | 分区号                                  |
| beginOffset  | 增量校验偏移量                          |
| rowCount     | 备用                                    |
| diffCount    | 校验差异记录行数                        |
| cost         | 校验总耗时（毫秒）                      |
| startTime    | 校验开始时间（yyyy-MM-dd HH:mm:ss.SSS） |
| endTime      | 校验截止时间（yyyy-MM-dd HH:mm:ss.SSS） |
| message      | 校验失败消息                            |
| keyInsertSet | 校验目标端缺少行主键集合                |
| keyUpdateSet | 校验目标端行数据不一致主键集合          |
| keyDeleteSet | 校验目标端多余行主键集合                |

##### **5.8.7 失败表修复报告说明**

失败修复报告为纯文本修复SQL内容

#### 5.9 注意事项

​	1、mysql数据库中char(n) 类型映射迁移到opengauss B库中为character(n)类型。char与character类型均为定长类型，mysql 查询char类型字段值默认不追加末尾空格。opengauss查询character默认追加空格。该特性保持一致则需要opengauss设置sql_mode，并取消pad_char_to_full_length模式

```
show dolphin.sql_mode;
                                                                    dolphin.sql_mode
---------------------------------------------------------------------------------------------------------------------------------------------------------
 sql_mode_strict,sql_mode_full_group,pipes_as_concat,ansi_quotes,no_zero_date,pad_char_to_full_length,auto_recompile_function,error_for_division_by_zero
```



## 6、增量校验
#### 6.1 下载debezium-connector插件

​	进入debezium官网或者maven仓库下载debezium-connector-mysql插件

```
官方发布版本地址：
https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/1.9.5.Final/debezium-connector-mysql-1.9.5.Final.jar
```

#### 6.2 配置kafka connect-standalone

​	将下载的debezium-connector-mysql 压缩包进行解压。

​	如果使用confluent，例如confluent-7.2.0 则解压到confluent-7.2.0/share/java目录

​	如果使用kafka，例如kafka_2.12-3.1.1则需在kafka根目录创建plugins目录，解压到该plugins目录。

```
# 将下载的debezium-connector-mysql-1.9.5.Final.jar文件直接解压
[root@xxxx xxx]#tar -zxf debezium-connector-mysql-1.9.5.Final-plugin.tar.gz
 etc/kafka/connect-standalone.properties
```

​	解压后debezium-connector-mysql-1.9.5.Final.jar文件可以直接删除。

​	配置connect-standalone.properties

	# confluent配置，打开connect-standalone配置文件，修改plugin.path配置项
	vi  /user_path/confluent-7.2.0/etc/kafka/connect-standalone.properties
	plugin.path=/usr/share/java,/user_path/confluent-7.2.0/share/java
```
# kafka_2.12-3.1.1配置，打开connect-standalone配置文件，修改plugin.path配置项
vi  /user_path/kafka_2.12-3.1.1/config/connect-standalone.properties
plugin.path=/user_path/kafka_2.12-3.1.1/plugins
```



#### 6.3 新增mysql-connect.properties

vi etc/kafka/mysql-conect.properties

```
name=mysql-connect-all # connecter name
connector.class=io.debezium.connector.mysql.MySqlConnector
database.hostname=127.0.0.1 # mysql datatabase 
database.port=3306 # mysql port
database.user=root # mysql user
database.password=test@123 # mysql password
database.server.id=1 # mysql server id
database.server.name=mysql_debezium_connect-all
database.whitelist=test # mysql database name
database.history.kafka.bootstrap.servers=127.0.0.1:9092 # kafka servers 
database.history.kafka.topic=mysql_test_topic-all # kafka connect history topic
include.schema.changes=true
transforms=Reroute
transforms.Reroute.type=io.debezium.transforms.ByLogicalTableRouter
transforms.Reroute.topic.regex=(.*)test(.*)
transforms.Reroute.topic.replacement=data_check_test_all # data incremnet check topic
```

**源端服务增量配置**

```
源端服务配置 修改application-source.yml文件
	spring.extract.debezium-enable #设置为true 开启增量校验
	spring.extract.debezium-topic #debezium监听Topic名称，对应mysql-connect.properties配置文件 transforms.Reroute.topic.replacement 配置项
    spring.extract.debezium-groupId: # 用于处理debezium监听的Topic数据 ，groupId消费Group设置
    spring.extract.debezium-time-period: 1 #增量校验时间周期 24*60 单位分钟
    spring.extract.debezium-num-period: 1000 #增量校验数量阈值，统计增量变更记录数量阀值，默认值1000 阀值应大于等于1000
```

#### 6.4 启动connect服务
```
# confluent启动
bin/connect-standalone -daemon etc/kafka/connect-standalone.properties etc/kafka/mysql-conect.properties
# 或者Kafka启动
bin/connect-standalone.sh -daemon config/connect-standalone.properties config/mysql-conect.properties
```

#### 6.5 启动校验服务

增量校验服务的启动，包含源端，目标端，校验端三个进程，具体启动命令参考全量校验启动方式。

增量校验目前只支持增删改数据校验，暂时不支持表结构变更校验（包括多表和少表）。



## 7、校验性能测试设计

性能测试设计，要求满足如上所示 “**环境要求**”。在50张表每张表1千万记录场景下，校验性能使用sysbench模型以及t_datacheck_templete模型，校验速率达到20万条/秒，其中使用t_datacheck_templete模型可以达到（150+M/s）

### 7.1 表设计

表包含数字，字符，日期，时间，枚举，文本，字符串多种格式，15个字段，表构建以及表数据构建采用sysbench进行批量构造。

```
CREATE TABLE `t_datacheck_templete` (
	`id` INT(11) UNSIGNED NOT NULL AUTO_INCREMENT,
	`c_int` INT(11) NULL DEFAULT NULL,
	`c_bigint` BIGINT(20) NULL DEFAULT NULL,
	`c_bigint2` BIGINT(20) NULL DEFAULT NULL,
	`c_char` CHAR(120) NULL DEFAULT NULL COLLATE 'utf8mb4_general_ci',
	`c_char2` CHAR(120) NULL DEFAULT NULL COLLATE 'utf8mb4_general_ci',
	`c_char3` CHAR(120) NULL DEFAULT NULL COLLATE 'utf8mb4_general_ci',
	`c_varchar` VARCHAR(300) NULL DEFAULT NULL COLLATE 'utf8mb4_general_ci',
	`c_varchar2` VARCHAR(300) NULL DEFAULT NULL COLLATE 'utf8mb4_general_ci',
	`c_text` TEXT NULL DEFAULT NULL COLLATE 'utf8mb4_general_ci',
	`c_text2` TEXT NULL DEFAULT NULL COLLATE 'utf8mb4_general_ci',
	`c_date` DATE NULL DEFAULT NULL,
	`c_time` TIME NULL DEFAULT NULL,
	`c_timestamp` TIMESTAMP NULL DEFAULT NULL,
	`c_float` FLOAT NULL DEFAULT NULL,
	`c_double` DOUBLE NULL DEFAULT NULL,
	`c_decimal` DECIMAL(20,6) NULL DEFAULT NULL,
	`c_decimal2` DECIMAL(20,6) NULL DEFAULT NULL,
	`c_enum` ENUM('Y','N') NULL DEFAULT NULL COLLATE 'utf8mb4_general_ci',
	PRIMARY KEY (`id`) USING BTREE
)
COLLATE='utf8mb4_general_ci'
ENGINE=InnoDB
;

```



### 7.2 kafka 调优配置

| 参数                | 建议值 | 描述                                                         |
| ------------------- | ------ | ------------------------------------------------------------ |
| num.network.threads | 128    | broker处理消息的最大线程数，主要处理网络IO，读写缓冲区数据。由于当前Kafka主要是网络瓶颈，所以该参数影响特别大。该参数默认值为3，此时对Kafka性能有决定性影响，当不断调大此参数时，性能会有比较大的提升。该参数的建议值是核数+1，但实际由于网卡瓶颈，该参数调到一定程度后对性能几乎没有影响。为了方便调试，我们可以直接将该参数定为核数+1甚至定为最大值（128）。 |
| num.io.threads      | 65     | broker处理磁盘IO的线程数，由于目前Kafka是网络瓶颈，所以磁盘IO的线程数影响并不是很大。目前典型场景单broker部署了23个Kafka盘，均为SAS盘，单盘性能较强。实际3~4个盘，就可以将网络IO跑到瓶颈，所以理论上IO线程数的修改对性能影响非常有限。该参数默认值为8，最高可以调到256。 |
| delete.topic.enable | true   | 建议打开topic删除策略，用于清理校验后topic历史数据           |

### 7.3  JVM 调优配置

JVM参数如下：-Xmx5G -Xms5G -XX:MaxMetaspaceSize=1G -XX:MetaspaceSize=1G -XX:+UseG1GC

根据当前机器可用内存大小和数据量大小适当调整。

### 7.4  数据校验 调优配置
数据校验工具主要耗时在数据抽取阶段，在数据校验抽取端调整以下配置，可以达到较高的数据校验性能。
| 参数                | 建议值 | 描述                                                         |
| ------------------- | ------ | ------------------------------------------------------------ |
| spring.check.maximum-topic-size  | 3      | 数据抽取端并发最大topic数量，该参数决定表并发抽取的数量，调大此参数时，性能会有一定提升，但是过大时会造成抽取端占用内存，等待数据库连接，造成资源不能合理使用，性能下降。该参数的建议值是3 |
| spring.check.maximum-table-slice-size      | 100000    | 数据抽取端表分片大小，该参数决定表内数据分片抽取的大小，当该参数较小时，频繁消耗数据库连接，成为性能瓶颈，调大该参数，可提升数据抽取性能，但是该值对内存影响较大，过大会造成性能下降。该参数的建议值是100000。 |
| spring.check.extend-maximum-pool-size | 10   | 表级分片抽取并发线程池设置，该参数决定处理分片抽取线程池的最大线程数，过大会造成频繁等待数据库连接，默认为10         |

### **7.5 数据校验速率计算参考**

```
校验速率 = 源端数据库大小 / 校验时间  
数据库大小：参考如下方式
校验时间：数据校验完成后，会自动统计校验耗时（cost time），并在check.log日志中打印 .
```

**数据库大小查看命令参考**

```
mysql> select concat(round(sum(data_length/1024/1024),2),'MB') as data from information_schema.tables where table_schema='test';
+-----------+
| data      |
+-----------+
| 2757.81MB |
+-----------+
1 row in set (0.01 sec)


opengauss:
test_check=> \l+
                                                                    List of databases
    Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges   |  Size   | Tablespace |                Description
------------+----------+----------+-------------+-------------+-----------------------+---------+------------+--------------------------------------------
 finance    | wangchao | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 13 MB   | pg_default |
 postgres   | wangchao | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 40 MB   | pg_default | default administrative connection database
 school     | wangchao | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 13 MB   | pg_default |
 template0  | wangchao | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/wangchao          +| 12 MB   | pg_default | default template for new databases
            |          |          |             |             | wangchao=CTc/wangchao |         |            |
 template1  | wangchao | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/wangchao          +| 12 MB   | pg_default | unmodifiable empty database
            |          |          |             |             | wangchao=CTc/wangchao |         |            |
 test_check | jack     | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 2847 MB | pg_default |
(6 rows)
```

## 8、过滤规则

### 8.1 规则配置模板

```
# 在校验服务配置文件中追加如下配置信息（config/application.yml）
rules:
  enable: true
  table:
    - name: white
      text: ^[a-z0-9]+$
    - name: black
      text: ^[a-z0-9]+$
  row:
    - name: ^[a-zA-Z][a-zA-Z_]+$
      text: 10,100
    - name: ^[a-zA-Z][a-zA-Z0-9_]+$
      text: 100,100
  column:
    - name: t_test_1
      text: id,exec_id,param,content
      attribute: include
    - name: t_test_2
      text: exec_id,param,content
      attribute: exclude
```

### 8.2 配置说明

| 配置项                 | 说明                                                         |
| ---------------------- | ------------------------------------------------------------ |
| rules.enable           | 开启或者关闭规则过滤 <br />值为  true  false                 |
| rules.table            | 配置表过滤规则<br/>可通过添加黑白名单，对当前数据库中待校验表进行过滤黑白名单为互斥规则，配置有白名单时，会忽略配置的黑名单规则。可同时配置多组白名单或者黑名单 |
| rules.table.name       | 配置表过滤规则<br />用于配置表级过滤规则的类型，是黑名单或者白名单 white black |
| rules.table.text       | 配置表级过滤规则<br />配置规则为正则表达式 ^[a-z0-9]+$，通过正则表达式过滤是否校验那些表。 |
| rules.row              | 配置行级过滤规则<br />行级规则会自动继承table规则类；行级规则允许配置多组行过滤规则；<br />规则等效于select * from table order by primaryKey asc limit offset,count;<br />对源端和目的端数据偏移造成的整体数据不一致，校验工具会报错，此时需要将offset，count 的范围扩大，再次进行校验确认。 |
| rules.row.name         | 配置行级过滤规则<br />该配置项通过正则表达式获取需要添加行过滤规则的表，即用于匹配添加行规则的表名称；name属性值不可为空，不可重复，为空则不生效。如果有多组规则的正则表达式匹配到同一张表，则以第一个匹配到的规则为准，其他规则自动忽略。 |
| rules.row.text         | 配置行级过滤规则<br />设置当前行过滤规则的具体数据筛选条件，配置格式为[offset,count]，必须为数字，否则该规则无效 |
| rules.column           | 配置列过滤规则<br />用于对表字段列进行过滤校验。可配置多组规则，name不可重复，重复会进行规则去重。 |
| rules.column.name      | 配置列过滤规则<br />列过滤字段的表名称                       |
| rules.column.text      | 配置列过滤规则<br />配置当前表待过滤的字段名称列表，如果某字段名称不属于当前表，则该字段不生效。 |
| rules.column.attribute | 配置列过滤规则<br />用于设置当前表过滤字段模式，include包含text配置的字段，exclude排除text配置的字段；<br />如果为include模式，text默认添加主键字段，不论text是否配置；<br />如果为exclude模式，text默认不添加主键字段，不论是否配置 |

**说明：rules.table表级规则优先级最高，完成表过滤后，行列规则再进行匹配。如果列规则配置的表未匹配到，则自动忽略该规则。**

## 9、与chameleon协同

### 9.1、 chameleon配置

chameleon 配置项设置：

with_datacheck：yes则迁移与校验协同任务打开

slice_size: 为数字选项，该选项用于设置chameleon对单一主键大表进行分片的大小设置，代表根据slice_size行记录进行文件分割

```
with_datacheck: yes
slice_size: 100000

```

### 9.2、 gs_datacheck协同配置

校验端配置修改

```
spring.check.floating-point-data-supply-zero: true # 当进行协同使用时，该配置必须设置为true,不进行协同时，则必须设置为false
spring.csv.sync: true # 用于打开chameleon协同同步配置，设置为true则打开
spring.csv.schema: test_schema # 设置当前同步迁移的MySQL端数据库名称 
spring.csv.path: 用于指定当前chameleon迁移数据缓存目录
```

源端配置修改

```
spring.extract.dataLoadMode: csv # 协同时修改源端加载模式为csv
spring.extract.schema: # 为源端MySQL迁移数据库名称
spring.extract.databaseType：MS # 与chameleon协同，该选项必须为MS。chameleon只支持MySQL迁移。
spring.datasource : #为数据源，源端可不进行配置
```

目标端配置修改

```
spring.extract.schema: # 为chameleon迁移到目标库的临时schema,即 _schemaName_tmp
```



### 9.3、chameleon与gs_datacheck 协同启动

```
步骤一：启动chameleon，开始迁移任务
	  chameleon init_replica --config opengaussv5 --source mysql
步骤二：启动校验抽取进程与校验进程
	sh extract-endpoints.sh start
	sh check-endpoint.sh start
```



## **10、 限制与约束**

```
1、JDK版本要求JDK11+
2、当前版本支持对源端和目标端为MySQL、oracle或openGauss的数据校验
3、当前版本仅支持数据校验，不支持表对象校验
4、MYSQL需要5.7+版本，opengauss要求3.0.0+，oracle目前支持版本19c，另外oracle驱动需用户手动添加到lib目录中。
5、当前版本对地理位置几何图形只支持openGauss到openGauss的数据校验，bit类型不支持openGauss到MySQL的校验
6、校验工具当前不支持校验中断(网络故障、kill进程等)自动恢复。
7、数据校验行级过滤规则配置，只支持[offset,count]指定范围内抽取，不支持排除[offset,count]范围之内的数据过滤。
8、行过滤规则抽取中间范围内数据（例如：[10,100]），如果源端在该范围之前的数据[0,10]发生删除操作，则会导致该表在指定范围内数据发生偏移，从而导致数据校验结果产生差异。此时需要扩大前置下标范围,以及增加相应的抽取数量。即[3,107]。
9、当对主键的update语句没有通过增量迁移同步到目的端 或 主键同步发生错误的时候，进行数据校验，源端update后的新数据和目标端的旧数据是两条独立的数据，对校验差异进行处理时，会生成两条语句，即对旧数据进行删除，对新数据做插入。此场景会将一条主键update语句拆分为两条语句（insert+delete）来执行，且分解到两个事务中执行，无法保证原子性。
10、增量校验不支持表级规则
11、增量校验不支持行级规则
12、增量校验目前只支持数据增删改校验，暂时不支持表结构（对象）校验（包括多表少表）
```

