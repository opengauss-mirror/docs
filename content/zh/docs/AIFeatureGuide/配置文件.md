# 配置文件<a name="ZH-CN_TOPIC_0000002258486288"></a>

用户可通过如下命令进行配置目录的初始化：

```
python3 startup.py service setup -c confpath
```

执行完该命令后 ，会在confpath目录下生成2个配置文件，分别为：

-   gaussmaster.conf：

    此文件中定义了GaussMaster服务需要用到的向量数据库、DBMind、log、WEB-SERVICE等信息。

-   model\_config.yaml：

    此文件定义了GaussMaster服务需要使用的大语言模型的信息。

gaussmaster.conf的详细信息说明如下：

```
# VECTOR部分用于配置向量数据库的连接信息
[VECTOR]
host =
port =
vector_dbname = # 本地知识库的数据库名
user =
metadatabase = # 用于存放GaussMaster生成的中间结果，例如问答记录、诊断报告等
l2_distance_threshold = 0.8 # 用于智能运维故障诊断模式中的故障树检索，需要根据向量模型的实际情况进行调整。
ssl = true # Using secure protocol by default, users must provide a certificate path.
ssl_certfile = (null) # The certificate file for ssl connections.
ssl_keyfile = (null) # Certificate private key file.
ssl_ca_file = (null)  # CA certificate to validate requests.

# DBMIND部分用于配置DBMind的连接信息
[DBMIND]
api_prefix = http(s)://***/v1/api/ # base URL ends with /v1/api/
ssl_certfile = (null) # The certificate file for ssl connections.
ssl_keyfile = (null) # Certificate private key file.
ssl_ca_file = (null)  # CA certificate to validate requests.

# WEB-SERVICE用于配置GaussMaster后台服务的地址，前端页面可通过该地址进行前后台绑定
[WEB-SERVICE]
host =   # Which host to bind for web service. '0.0.0.0' means to bind all.
port =   # Port to listen for web service.
ssl_certfile = (null) # The certificate file for ssl connections.
ssl_keyfile = (null) # Certificate private key file.
ssl_ca_file = (null)  # CA certificate to validate requests.

# LOG部分用于配置日志信息
[LOG]
maxbytes = 10485760 # Default is 10Mb. Maximum size of a single log file. If maxbytes is zero, the file grows indefinitely.
backupcount = 1 # Number of backups of log files.
level = DEBUG  # Options: DEBUG, INFO, WARNING, ERROR.
log_directory = logs  # Directory to log.

# TIMEZONE部分用于GaussMaster服务的默认时区
[TIMEZONE]
tz = UTC+8 # only supports UTC, example: UTC-8, UTC+8, UTC-8:35

# SAFETY部分用于配置是否开启敏感问题检查
[SAFETY]
safety_check = false  # Whether to check the question involving unsafe inquiry
```

当前版本GaussMaster只支持在线模型的调用，model\_config.yaml的详细信息说明如下：

```
# 默认使用的大模型，需要将online_llm中对应模型的enable按钮改为True
model_name: pangu_sigma_unify_plugin_38b

# 向量模型的API地址
embedding_model:
  enable: True
  model_name: bge-large-finetune
  api_type: bge-large
  api_url: http://*.*.*.*:*/get_embedding_result
# reranker模型的API地址
reranker_model:
  enable: True
  model_name: bge-reranker-finetune
  api_type: bge-reranker
  api_url: http://*.*.*.*:*/get_reranker_result

# 大语言模型的API地址，要启用什么大模型，需要将对应的enable改为True，不使用的改为False。
online_llm:
  pangu_sigma_unify_plugin_38b:
    enable: True
    api_type: Pangu
    api_url: http://*.*.*.*:*/chat/completions
    recommended_config:
      temperature: 0.7
      top_p: 1.0
  pangu_cloud_sigma_unify_plugin_38b:
    enable: False
    api_type: PanguCloud
    api_url: http://*.*.*.*:*/chat/completions
    recommended_config:
      temperature: 0.7
      top_p: 1.0
  Baichuan2-13B-Chat:
    enable: False
    api_type: Baichuan
    api_url: http://*.*.*.*:*/get_qa_baichuan
    recommended_config:
      temperature: 0.7
      top_p: 1.0
  chatglm3-6b:
    enable: False
    api_type: Chatglm
    api_url: http://*.*.*.*:*/get_qa_chatglm
    recommended_config:
      temperature: 0.7
      top_p: 1.0
  Llama3-8B-Chinese-Chat:
    enable: False
    api_type: Llama3
    api_url: http://*.*.*.*:*/get_llm_result_llama3
    recommended_config:
      temperature: 0.7
      top_p: 1.0
```

